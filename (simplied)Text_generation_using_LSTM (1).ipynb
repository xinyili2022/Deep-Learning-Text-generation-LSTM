{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "Qmjrqjqurmj9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,LSTM, Dropout\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load text and covert to lowercase\n",
        "upload = \"wonderland_simplied.txt\"\n",
        "text = open(upload, 'r', encoding='latin-1').read()\n",
        "\n",
        "text = text.lower() #vocabulary reduction"
      ],
      "metadata": {
        "id": "eEVH7tCgth1A"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_chars = sorted(list(set(text)))\n",
        "chars_to_ints = dict((c, i) for i, c in enumerate(unique_chars))\n",
        "ints_to_chars = dict((i, c) for i, c in enumerate(unique_chars))"
      ],
      "metadata": {
        "id": "IR5e3SstuLFy"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(unique_chars)\n",
        "print(chars_to_ints)\n",
        "print(ints_to_chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFXNqMVMuhu-",
        "outputId": "03fae2d6-cf33-433c-f3b5-48036d38aaf8"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\n', ' ', '!', '(', ')', '*', ',', '-', '.', '0', '3', ':', ';', '?', '[', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\x91', '\\x92', '\\x93', '\\x94']\n",
            "{'\\n': 0, ' ': 1, '!': 2, '(': 3, ')': 4, '*': 5, ',': 6, '-': 7, '.': 8, '0': 9, '3': 10, ':': 11, ';': 12, '?': 13, '[': 14, '_': 15, 'a': 16, 'b': 17, 'c': 18, 'd': 19, 'e': 20, 'f': 21, 'g': 22, 'h': 23, 'i': 24, 'j': 25, 'k': 26, 'l': 27, 'm': 28, 'n': 29, 'o': 30, 'p': 31, 'q': 32, 'r': 33, 's': 34, 't': 35, 'u': 36, 'v': 37, 'w': 38, 'x': 39, 'y': 40, 'z': 41, '\\x91': 42, '\\x92': 43, '\\x93': 44, '\\x94': 45}\n",
            "{0: '\\n', 1: ' ', 2: '!', 3: '(', 4: ')', 5: '*', 6: ',', 7: '-', 8: '.', 9: '0', 10: '3', 11: ':', 12: ';', 13: '?', 14: '[', 15: '_', 16: 'a', 17: 'b', 18: 'c', 19: 'd', 20: 'e', 21: 'f', 22: 'g', 23: 'h', 24: 'i', 25: 'j', 26: 'k', 27: 'l', 28: 'm', 29: 'n', 30: 'o', 31: 'p', 32: 'q', 33: 'r', 34: 's', 35: 't', 36: 'u', 37: 'v', 38: 'w', 39: 'x', 40: 'y', 41: 'z', 42: '\\x91', 43: '\\x92', 44: '\\x93', 45: '\\x94'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "text[:10] #learn the meaning of text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "T_CRttbcwMhc",
        "outputId": "e2c05b6b-1dba-4453-eb97-173bf486dcde"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'*** start '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(unique_chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONyHhcC-4KHD",
        "outputId": "a876cb00-84a1-4be7-ec08-3bb48862ddcf"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4I1yqUXyuhwD",
        "outputId": "e33f19e2-3499-4e31-8257-c82c3424dcf1"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32182"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_in = text[1:1 + 50]\n",
        "print(\"seq_in:\",seq_in)\n",
        "seq_out = text[51]\n",
        "print(\"seq_out:\",seq_out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfMzKFPEyMKA",
        "outputId": "f462a0e4-debb-4bcc-9cd8-43245e39ad24"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "seq_in: ** start of this project gutenberg ebook alices a\n",
            "seq_out: d\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataX=[]\n",
        "print(seq_in)\n",
        "dataX.append([chars_to_ints[char] for char in seq_in])\n",
        "print(dataX)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1lsKRfqz6vt",
        "outputId": "43eca86e-46d7-45bc-c571-ad821ebd4eca"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "** start of this project gutenberg ebook alices a\n",
            "[[5, 5, 1, 34, 35, 16, 33, 35, 1, 30, 21, 1, 35, 23, 24, 34, 1, 31, 33, 30, 25, 20, 18, 35, 1, 22, 36, 35, 20, 29, 17, 20, 33, 22, 1, 20, 17, 30, 30, 26, 1, 16, 27, 24, 18, 20, 43, 34, 1, 16]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataY = []\n",
        "print(seq_out)\n",
        "dataY.append(chars_to_ints[seq_out])\n",
        "print(dataY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qyKC4Ip0l21",
        "outputId": "038fe114-dcc6-488a-8f06-a366af1bea32"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "d\n",
            "[19]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 100\n",
        "dataX, dataY = [], []"
      ],
      "metadata": {
        "id": "3-KdQ8Yr18-h"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, len(text) - seq_length, 1):\n",
        "    seq_in = text[i:i + seq_length]\n",
        "    seq_out = text[i + seq_length]\n",
        "    dataX.append([chars_to_ints[char] for char in seq_in])\n",
        "    dataY.append(chars_to_ints[seq_out])"
      ],
      "metadata": {
        "id": "haSKAfZfv5VE"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_patterns = len(dataX)\n",
        "print(n_patterns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yje8s7IAzlXo",
        "outputId": "934c2565-2ad1-49dc-95f3-fa46f4466af2"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32082\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape X to be [samples, time steps, features]\n",
        "X = np.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "#X"
      ],
      "metadata": {
        "id": "ru6wgFhFzm0Z"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize\n",
        "X = X / float(len(unique_chars))\n",
        "#print(X)"
      ],
      "metadata": {
        "id": "hZsaDXPa4aVZ"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "encoder = OneHotEncoder(sparse=False, categories='auto')\n",
        "y = encoder.fit_transform(np.array(dataY).reshape(-1, 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJS29cq75nsr",
        "outputId": "b5ce6afd-59e4-4cdf-b000-682f47d625bc"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.8))\n",
        "\n",
        "model.add(LSTM(256))\n",
        "model.add(Dropout(0.8))\n",
        "\n",
        "model.add(Dense(len(unique_chars), activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n"
      ],
      "metadata": {
        "id": "APNe28qa4ali"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model (you can adjust epochs and batch_size)\n",
        "model.fit(X, y, epochs=10, batch_size=2000, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5gWeqx06-sZ",
        "outputId": "a165d63e-e0f6-49c7-8ada-946a118cbde2"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "17/17 [==============================] - 232s 13s/step - loss: 3.4299\n",
            "Epoch 2/10\n",
            "17/17 [==============================] - 227s 13s/step - loss: 3.1902\n",
            "Epoch 3/10\n",
            "17/17 [==============================] - 228s 13s/step - loss: 3.1390\n",
            "Epoch 4/10\n",
            "17/17 [==============================] - 226s 13s/step - loss: 3.1156\n",
            "Epoch 5/10\n",
            "17/17 [==============================] - 226s 13s/step - loss: 3.0963\n",
            "Epoch 6/10\n",
            "17/17 [==============================] - 226s 13s/step - loss: 3.0838\n",
            "Epoch 7/10\n",
            "17/17 [==============================] - 226s 13s/step - loss: 3.0747\n",
            "Epoch 8/10\n",
            "17/17 [==============================] - 226s 13s/step - loss: 3.0720\n",
            "Epoch 9/10\n",
            "17/17 [==============================] - 226s 13s/step - loss: 3.0646\n",
            "Epoch 10/10\n",
            "17/17 [==============================] - 227s 13s/step - loss: 3.0602\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7bab9d7c79d0>"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#generating the text\n",
        "# pick a random seed\n",
        "random = np.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[random]\n",
        "print(\"\\\"\", ''.join([ints_to_chars[value] for value in pattern]), \"\\\"\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zltjpJ_Dz3I6",
        "outputId": "e99353ce-b874-4b92-f622-d9e512cbaeb4"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\" ere me?\n",
            "\n",
            "well, perhaps not, said alice in a soothing tone: dont be angry\n",
            "about it. and yet i wi \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#generate based on the input text\n",
        "def generate_text(seed_text, n_chars):\n",
        "    seed_text=seed_text.lower()\n",
        "    generated_text = seed_text\n",
        "    pattern = [chars_to_ints[char] for char in seed_text]\n",
        "\n",
        "    while len(pattern) < 100:\n",
        "        pattern.insert(0, 0)\n",
        "\n",
        "    output=seed_text\n",
        "    for i in range(n_chars):\n",
        "        x = np.reshape(pattern, (1, len(pattern), 1))\n",
        "        x = x / float(len(unique_chars))\n",
        "        prediction = model.predict(x, verbose=0)\n",
        "        index = np.argmax(prediction)\n",
        "        result = ints_to_chars[index]\n",
        "        output += result\n",
        "        pattern.append(index)\n",
        "        pattern = pattern[1:len(pattern)]\n",
        "    return output"
      ],
      "metadata": {
        "id": "-NtcCJOXwFmW"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(\"Alice was beginning\",200)) # I don't know how to fix this problem, and I found from the comments there are a lot of people hving same question"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mct9w1qd2Yys",
        "outputId": "2920263d-84d8-4e05-8909-7b6e75867449"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alice was beginning                                                                                                                                                                                                        \n"
          ]
        }
      ]
    }
  ]
}
