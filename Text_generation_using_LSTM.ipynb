{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Qmjrqjqurmj9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,LSTM, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load text and covert to lowercase\n",
        "filename = \"wonderland.txt\"\n",
        "raw_text = open(filename, 'r', encoding='latin-1').read()\n",
        "#raw_text = open(filename).read()\n",
        "raw_text = raw_text.lower() #vocabulary reduction"
      ],
      "metadata": {
        "id": "eEVH7tCgth1A"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "metadata": {
        "id": "IR5e3SstuLFy"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chars)\n",
        "print(char_to_int)\n",
        "print(int_to_char)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFXNqMVMuhu-",
        "outputId": "67edc83a-5263-4327-eb9b-63128801b48e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\n', ' ', '!', '(', ')', '*', ',', '-', '.', '0', '3', ':', ';', '?', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\x91', '\\x92', '\\x93', '\\x94']\n",
            "{'\\n': 0, ' ': 1, '!': 2, '(': 3, ')': 4, '*': 5, ',': 6, '-': 7, '.': 8, '0': 9, '3': 10, ':': 11, ';': 12, '?': 13, '[': 14, ']': 15, '_': 16, 'a': 17, 'b': 18, 'c': 19, 'd': 20, 'e': 21, 'f': 22, 'g': 23, 'h': 24, 'i': 25, 'j': 26, 'k': 27, 'l': 28, 'm': 29, 'n': 30, 'o': 31, 'p': 32, 'q': 33, 'r': 34, 's': 35, 't': 36, 'u': 37, 'v': 38, 'w': 39, 'x': 40, 'y': 41, 'z': 42, '\\x91': 43, '\\x92': 44, '\\x93': 45, '\\x94': 46}\n",
            "{0: '\\n', 1: ' ', 2: '!', 3: '(', 4: ')', 5: '*', 6: ',', 7: '-', 8: '.', 9: '0', 10: '3', 11: ':', 12: ';', 13: '?', 14: '[', 15: ']', 16: '_', 17: 'a', 18: 'b', 19: 'c', 20: 'd', 21: 'e', 22: 'f', 23: 'g', 24: 'h', 25: 'i', 26: 'j', 27: 'k', 28: 'l', 29: 'm', 30: 'n', 31: 'o', 32: 'p', 33: 'q', 34: 'r', 35: 's', 36: 't', 37: 'u', 38: 'v', 39: 'w', 40: 'x', 41: 'y', 42: 'z', 43: '\\x91', 44: '\\x92', 45: '\\x93', 46: '\\x94'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "raw_text[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "T_CRttbcwMhc",
        "outputId": "f2845578-a6c6-4081-927e-e2c54010b049"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'*** start '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONyHhcC-4KHD",
        "outputId": "3090b4b7-817b-4ee7-9817-be9b6dbe83fe"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(raw_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4I1yqUXyuhwD",
        "outputId": "efdcead2-343d-4a98-9c9b-c645a2aea0be"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "144515"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_in = raw_text[1:1 + 50]\n",
        "print(\"seq_in:\",seq_in)\n",
        "seq_out = raw_text[51]\n",
        "print(\"seq_out:\",seq_out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfMzKFPEyMKA",
        "outputId": "bafe4ab9-92fc-4fd9-a640-39b11cd7560c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "seq_in: ** start of this project gutenberg ebook alices a\n",
            "seq_out: d\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataX=[]\n",
        "print(seq_in)\n",
        "dataX.append([char_to_int[char] for char in seq_in])\n",
        "print(dataX)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1lsKRfqz6vt",
        "outputId": "be875e18-6574-46eb-be04-7059c07d47f7"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "** start of this project gutenberg ebook alices a\n",
            "[[5, 5, 1, 35, 36, 17, 34, 36, 1, 31, 22, 1, 36, 24, 25, 35, 1, 32, 34, 31, 26, 21, 19, 36, 1, 23, 37, 36, 21, 30, 18, 21, 34, 23, 1, 21, 18, 31, 31, 27, 1, 17, 28, 25, 19, 21, 44, 35, 1, 17]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataY = []\n",
        "print(seq_out)\n",
        "dataY.append(char_to_int[seq_out])\n",
        "print(dataY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qyKC4Ip0l21",
        "outputId": "76dcf1f0-6e75-4965-fda4-c617491218f8"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "d\n",
            "[20]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 100\n",
        "dataX, dataY = [], []"
      ],
      "metadata": {
        "id": "3-KdQ8Yr18-h"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, len(raw_text) - seq_length, 1):\n",
        "    seq_in = raw_text[i:i + seq_length]\n",
        "    seq_out = raw_text[i + seq_length]\n",
        "    dataX.append([char_to_int[char] for char in seq_in])\n",
        "    dataY.append(char_to_int[seq_out])"
      ],
      "metadata": {
        "id": "haSKAfZfv5VE"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_patterns = len(dataX)\n",
        "print(n_patterns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yje8s7IAzlXo",
        "outputId": "7828cdea-dff5-4e8b-9160-1a3d61030041"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "144415\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape X to be [samples, time steps, features]\n",
        "X = np.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "#X"
      ],
      "metadata": {
        "id": "ru6wgFhFzm0Z"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize\n",
        "X = X / float(len(chars))\n",
        "#print(X)"
      ],
      "metadata": {
        "id": "hZsaDXPa4aVZ"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "encoder = OneHotEncoder(sparse=False, categories='auto')\n",
        "y = encoder.fit_transform(np.array(dataY).reshape(-1, 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJS29cq75nsr",
        "outputId": "f33b6537-5e5c-42b6-95cb-aad8506eafc9"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(LSTM(256))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n"
      ],
      "metadata": {
        "id": "APNe28qa4ali"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model (you can adjust epochs and batch_size)\n",
        "model.fit(X, y, epochs=10, batch_size=2000, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5gWeqx06-sZ",
        "outputId": "2dfa4e4e-742a-49c6-bbe8-b3628b350035"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "73/73 [==============================] - 1004s 14s/step - loss: 3.1323\n",
            "Epoch 2/10\n",
            "73/73 [==============================] - 995s 14s/step - loss: 3.0569\n",
            "Epoch 3/10\n",
            "73/73 [==============================] - 996s 14s/step - loss: 3.0314\n",
            "Epoch 4/10\n",
            "73/73 [==============================] - 997s 14s/step - loss: 2.9563\n",
            "Epoch 5/10\n",
            "73/73 [==============================] - 1009s 14s/step - loss: 2.8644\n",
            "Epoch 6/10\n",
            "73/73 [==============================] - 997s 14s/step - loss: 2.7761\n",
            "Epoch 7/10\n",
            "73/73 [==============================] - 999s 14s/step - loss: 2.7150\n",
            "Epoch 8/10\n",
            "73/73 [==============================] - 1006s 14s/step - loss: 2.6568\n",
            "Epoch 9/10\n",
            "73/73 [==============================] - 1003s 14s/step - loss: 2.6055\n",
            "Epoch 10/10\n",
            "73/73 [==============================] - 999s 14s/step - loss: 2.5590\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7bab9f529b70>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#generating the text\n",
        "# pick a random seed\n",
        "start = np.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print (\"Seed:\")\n",
        "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zltjpJ_Dz3I6",
        "outputId": "c63aee9b-2163-40ae-e288-85eb8c77d55b"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed:\n",
            "\" only knew how to begin.\n",
            "for, you see, so many out-of-the-way things had happened lately,\n",
            "that alice \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#generate based on the input text\n",
        "def generate_text(seed_text, n_chars=100):\n",
        "    seed_text=seed_text.lower()\n",
        "    generated_text = seed_text\n",
        "\n",
        "    for i in range(n_chars):\n",
        "        x_pred = np.array([char_to_int[c] for c in seed_text])\n",
        "        x_pred = np.reshape(x_pred, (1, len(x_pred), 1)) / float(len(chars))\n",
        "\n",
        "        prediction = model.predict(x_pred, verbose=0)\n",
        "        index = np.argmax(prediction)\n",
        "        char_out = int_to_char[index]\n",
        "\n",
        "        generated_text += char_out\n",
        "        seed_text = seed_text[1:] + char_out\n",
        "\n",
        "\n",
        "    return generated_text\n",
        "\n"
      ],
      "metadata": {
        "id": "-NtcCJOXwFmW"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(\"Alice was beginning\",200)) # I don't know how to fix this problem, and I found from the comments there are a lot of people hving same question"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mct9w1qd2Yys",
        "outputId": "46bb7b2f-87bc-4276-fc43-9c95bc52f3b6"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alice was beginning to the cane the taid the taid the taid the taid the taid the taid the taid the taid the taid the taid the taid the taid the taid the taid the taid the taid the taid the taid the taid the taid the tai\n"
          ]
        }
      ]
    }
  ]
}